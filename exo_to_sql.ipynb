{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import json\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth',1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create db with exoplanets data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data source: https://www.kaggle.com/datasets/adityamishraml/nasaexoplanets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exoplanets_df = pd.read_csv('cleaned_5250.csv')\n",
    "# conn = sqlite3.connect('./databases/exoplanets_db.db')\n",
    "# exoplanets_df.to_sql('exoplanets',conn,if_exists='replace',index=False)\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x74cbc8331340>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect('./databases/exoplanets_db.db')\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(f\"SELECT * FROM exoplanets LIMIT 5;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('11 Comae Berenices b', 304.0, 4.72307, 'Gas Giant', 2007, 19.4, 'Jupiter', 1.08, 'Jupiter', 1.29, 0.8925394, 0.23, 'Radial Velocity')\n",
      "('11 Ursae Minoris b', 409.0, 5.013, 'Gas Giant', 2009, 14.74, 'Jupiter', 1.09, 'Jupiter', 1.53, 1.4, 0.08, 'Radial Velocity')\n",
      "('14 Andromedae b', 246.0, 5.23133, 'Gas Giant', 2008, 4.8, 'Jupiter', 1.15, 'Jupiter', 0.83, 0.5086927, 0.0, 'Radial Velocity')\n",
      "('14 Herculis b', 58.0, 6.61935, 'Gas Giant', 2002, 8.13881, 'Jupiter', 1.12, 'Jupiter', 2.773069, 4.8, 0.37, 'Radial Velocity')\n",
      "('16 Cygni B b', 69.0, 6.215, 'Gas Giant', 1996, 1.78, 'Jupiter', 1.2, 'Jupiter', 1.66, 2.2, 0.68, 'Radial Velocity')\n"
     ]
    }
   ],
   "source": [
    "for row in cursor:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x74cbc8331340>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\"PRAGMA table_info(exoplanets)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'name', 'TEXT', 0, None, 0)\n",
      "(1, 'distance', 'REAL', 0, None, 0)\n",
      "(2, 'stellar_magnitude', 'REAL', 0, None, 0)\n",
      "(3, 'planet_type', 'TEXT', 0, None, 0)\n",
      "(4, 'discovery_year', 'INTEGER', 0, None, 0)\n",
      "(5, 'mass_multiplier', 'REAL', 0, None, 0)\n",
      "(6, 'mass_wrt', 'TEXT', 0, None, 0)\n",
      "(7, 'radius_multiplier', 'REAL', 0, None, 0)\n",
      "(8, 'radius_wrt', 'TEXT', 0, None, 0)\n",
      "(9, 'orbital_radius', 'REAL', 0, None, 0)\n",
      "(10, 'orbital_period', 'REAL', 0, None, 0)\n",
      "(11, 'eccentricity', 'REAL', 0, None, 0)\n",
      "(12, 'detection_method', 'TEXT', 0, None, 0)\n"
     ]
    }
   ],
   "source": [
    "for row in cursor:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"\"\"\n",
    "SELECT discovery_year, AVG(\"Mass (MJ)\") AS average_mass\n",
    "FROM exoplanets\n",
    "GROUP BY \"Disc. Year\"\n",
    "ORDER BY \"Disc. Year\";\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"CREATE TABLE reference_planets (name TEXT, mass REAL);\"\n",
    "\n",
    "# cursor.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cursor.execute(\"DELETE  from reference_planets where 1==1;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert1 = \"\"\"\n",
    "# INSERT INTO reference_planets (name, mass) VALUES ('Jupiter', 1.898e27);\n",
    "# \"\"\"\n",
    "# insert2 = \"\"\"\n",
    "# INSERT INTO reference_planets (name, mass) VALUES ('Earth', 5.972e24);\n",
    "# \"\"\"\n",
    "# cursor.execute(insert1);cursor.execute(insert2)\n",
    "# conn.commit()\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT * FROM reference_planets;\")\n",
    "for row in cursor:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_query(query,verbose=False):\n",
    "    cursor.execute(query)\n",
    "    if verbose:\n",
    "        for row in cursor:\n",
    "            print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many exoplanets were discovered using each method? (Order by the number of discoveries)\n",
    "query=f\"\"\"\n",
    "SELECT \n",
    "    e.detection_method,\n",
    "    COUNT(*) AS count_exoplanets\n",
    "FROM exoplanets e\n",
    "GROUP BY e.detection_method\n",
    "ORDER BY count_exoplanets DESC;  \n",
    "\"\"\"\n",
    "test_query(query,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Which exoplanets are located in the habitable zone (typically 0.95 to 1.37 AU for stars similar to the Sun)?\n",
    "query=f\"\"\"\n",
    "SELECT \n",
    "    e.name,\n",
    "    e.orbital_radius\n",
    "FROM exoplanets e\n",
    "WHERE e.orbital_radius BETWEEN 0.95 AND 1.37;\n",
    "\"\"\"\n",
    "test_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List exoplanets that are within 20 light-years of Earth.\n",
    "query=f\"\"\"\n",
    "SELECT \n",
    "    e.name,\n",
    "    e.distance\n",
    "FROM exoplanets e\n",
    "WHERE e.distance < 20;  -- Within 20 light-years\n",
    "\"\"\"\n",
    "test_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exoplanets_df[exoplanets_df.name=='11 Comae Berenices b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find exoplanets with eccentricity values greater than 0.5, indicating more elongated orbits. Order by highest eccentricity.\n",
    "query=f\"\"\"\n",
    "SELECT \n",
    "    e.name,\n",
    "    e.eccentricity,\n",
    "    e.orbital_period\n",
    "FROM exoplanets e\n",
    "WHERE e.eccentricity > 0.5\n",
    "ORDER BY e.eccentricity DESC;  -- Order by highest eccentricity\n",
    "\"\"\"\n",
    "test_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find exoplanets with mass greater than a certain threshold (e.g., 5 MJ).\n",
    "query=f\"\"\"\n",
    "WITH MassFactors AS (\n",
    "    SELECT \n",
    "        MAX(CASE WHEN name = 'Earth' THEN mass END) AS earth_mass,\n",
    "        MAX(CASE WHEN name = 'Jupiter' THEN mass END) AS jupiter_mass\n",
    "    FROM reference_planets\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    e.name,\n",
    "    CASE \n",
    "        WHEN e.mass_wrt = 'Earth' THEN e.mass_multiplier * r.mass  -- Mass in Earth masses\n",
    "        WHEN e.mass_wrt = 'Jupiter' THEN e.mass_multiplier * r.mass * (SELECT jupiter_mass / earth_mass FROM MassFactors)  -- Convert to Earth masses\n",
    "    END AS mass_in_earth_masses\n",
    "FROM exoplanets e\n",
    "JOIN reference_planets r ON e.mass_wrt = r.name\n",
    "WHERE (CASE \n",
    "            WHEN e.mass_wrt = 'Earth' THEN e.mass_multiplier * r.mass\n",
    "            WHEN e.mass_wrt = 'Jupiter' THEN e.mass_multiplier * r.mass * (SELECT jupiter_mass / earth_mass FROM MassFactors)\n",
    "        END) > 5;-- Mass threshold in Earth masses\n",
    "\"\"\"\n",
    "test_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find exoplanets with mass greater than 5 Earth masses\n",
    "query=f\"\"\"\n",
    "WITH MassFactors AS (\n",
    "    SELECT \n",
    "        MAX(CASE WHEN name = 'Earth' THEN mass END) AS earth_mass,\n",
    "        MAX(CASE WHEN name = 'Jupiter' THEN mass END) AS jupiter_mass\n",
    "    FROM reference_planets\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    e.name,\n",
    "    CASE \n",
    "        WHEN e.mass_wrt = 'Earth' THEN e.mass_multiplier * r.mass  -- Mass in Earth masses\n",
    "        WHEN e.mass_wrt = 'Jupiter' THEN e.mass_multiplier * r.mass * (SELECT jupiter_mass / earth_mass FROM MassFactors)  -- Convert to Earth masses\n",
    "    END AS mass_in_earth_masses\n",
    "FROM exoplanets e\n",
    "JOIN reference_planets r ON e.mass_wrt = r.name\n",
    "WHERE (CASE \n",
    "            WHEN e.mass_wrt = 'Earth' THEN e.mass_multiplier * r.mass\n",
    "            WHEN e.mass_wrt = 'Jupiter' THEN e.mass_multiplier * r.mass * (SELECT jupiter_mass / earth_mass FROM MassFactors)\n",
    "        END) > 5;  -- Mass threshold in Earth masses\n",
    "  -- Mass threshold in Earth masses\n",
    "\"\"\"\n",
    "test_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "19.4*1.898e+27*(1.898e+27/5.972e+24) # perhaps was overestimated in db!!! query correct,though\n",
    "#('Jupiter', 1.898e+27)\n",
    "#('Earth', 5.972e+24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the 5 closest exoplanets that are also the brightest.\n",
    "query=f\"\"\"\n",
    "SELECT \n",
    "    e.name,\n",
    "    e.distance,\n",
    "    e.stellar_magnitude\n",
    "FROM exoplanets e\n",
    "WHERE e.distance IS NOT NULL and e.stellar_magnitude IS NOT NULL\n",
    "ORDER BY e.distance ASC, e.stellar_magnitude ASC  -- Closest and brightest\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "test_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average orbital radius for each type of exoplanet. Order by average orbital radius descending.\n",
    "query=f\"\"\"\n",
    "SELECT \n",
    "    e.planet_type,\n",
    "    AVG(e.orbital_radius) AS avg_orbital_radius\n",
    "FROM exoplanets e\n",
    "GROUP BY e.planet_type\n",
    "ORDER BY avg_orbital_radius DESC;  \n",
    "\"\"\"\n",
    "test_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many exoplanets of each type were discovered each year. Order by year ascending and count descending.\n",
    "query=f\"\"\"\n",
    "SELECT \n",
    "    e.discovery_year,\n",
    "    e.planet_type,\n",
    "    COUNT(*) AS count\n",
    "FROM exoplanets e\n",
    "GROUP BY e.discovery_year, e.planet_type\n",
    "ORDER BY e.discovery_year, count DESC;  \n",
    "\"\"\"\n",
    "test_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find exoplanets with an eccentricity greater than 0.6 and an orbital period longer than 200 days.\n",
    "query=f\"\"\"\n",
    "SELECT \n",
    "    e.name,\n",
    "    e.eccentricity,\n",
    "    e.orbital_period\n",
    "FROM exoplanets e\n",
    "WHERE e.eccentricity > 0.6 AND e.orbital_period > 200\n",
    "ORDER BY e.eccentricity DESC; \n",
    "\"\"\"\n",
    "test_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all exoplanets discovered in the last 5 years, sorted by discovery year.\n",
    "query=f\"\"\"\n",
    "SELECT \n",
    "    e.name,\n",
    "    e.discovery_year\n",
    "FROM exoplanets e\n",
    "WHERE e.discovery_year >= strftime('%Y', 'now') - 5  -- Last 5 years\n",
    "ORDER BY e.discovery_year DESC;  -- Most recent first\n",
    "\"\"\"\n",
    "test_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Identify the most common types of exoplanets among the top 10 brightest, order by frequency of planet types.\n",
    "query=f\"\"\"\n",
    "WITH BrightestExoplanets AS (\n",
    "    SELECT \n",
    "        e.name,\n",
    "        e.planet_type,\n",
    "        e.stellar_magnitude\n",
    "    FROM exoplanets e\n",
    "    ORDER BY e.stellar_magnitude ASC  -- Brightest first\n",
    "    LIMIT 10\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    planet_type,\n",
    "    COUNT(*) AS count\n",
    "FROM BrightestExoplanets\n",
    "GROUP BY planet_type\n",
    "ORDER BY count DESC;\n",
    "\"\"\"\n",
    "test_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the relationship between the discovery year and the average stellar magnitude of exoplanets discovered each year.\n",
    "query=f\"\"\"\n",
    "SELECT \n",
    "    e.discovery_year,\n",
    "    AVG(e.stellar_magnitude) AS avg_stellar_magnitude\n",
    "FROM exoplanets e\n",
    "GROUP BY e.discovery_year\n",
    "ORDER BY e.discovery_year;  -- Order by discovery year\n",
    "\n",
    "\"\"\"\n",
    "test_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query(\"\"\"\n",
    "SELECT planet_type, name, radius_multiplier\n",
    "FROM exoplanets\n",
    "WHERE (planet_type, radius_multiplier) IN (\n",
    "    SELECT planet_type, radius_multiplier\n",
    "    FROM exoplanets\n",
    "    ORDER BY planet_type, radius_multiplier DESC\n",
    ")\n",
    "GROUP BY planet_type\n",
    "LIMIT 2;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query(\"\"\"\n",
    "SELECT discovery_year, \n",
    "SUM(mass_multiplier * (SELECT mass FROM reference_planets WHERE name = mass_wrt)) AS total_mass\n",
    "FROM exoplanets\n",
    "WHERE mass_multiplier IS NOT NULL\n",
    "GROUP BY discovery_year\n",
    "ORDER BY total_mass DESC\n",
    "LIMIT 5;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing query results in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_sql_df = pd.read_csv('Exoplanets-OG20 - Sheet1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_sql_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_queries=list(generated_sql_df['answer'])\n",
    "len(sql_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_queries = []\n",
    "\n",
    "# Process each query\n",
    "for idx, query in enumerate(sql_queries):\n",
    "    try:\n",
    "        test_query(query)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        error_queries.append({'query': query, 'idx': idx, 'exception': type(e).__name__})\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query('SELECT discovery_year, name, orbital_period FROM exoplanets WHERE (discovery_year, name, orbital_period) IN (   SELECT discovery_year, name, orbital_period    FROM exoplanets    ORDER BY discovery_year, orbital_period DESC) GROUP BY discovery_year LIMIT 3;', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query('SELECT e.name, e.orbital_radius, e.mass_multiplier * r.mass AS mass FROM exoplanets e JOIN reference_planets r ON e.mass_wrt = r.name WHERE e.orbital_radius BETWEEN 0.5 AND 1.5  ORDER BY mass DESC;', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query(\"\"\"WITH DetectionTrends AS (\n",
    "    SELECT \n",
    "        discovery_year,\n",
    "        detection_method,\n",
    "        COUNT(*) AS method_count\n",
    "    FROM exoplanets\n",
    "    GROUP BY discovery_year, detection_method\n",
    "),\n",
    "RankedTrends AS (\n",
    "    SELECT \n",
    "        discovery_year,\n",
    "        detection_method,\n",
    "        method_count, RANK() OVER (PARTITION BY discovery_year ORDER BY method_count DESC) AS method_rank FROM DetectionTrends) SELECT  discovery_year, detection_method, method_count, method_rank FROM RankedTrends WHERE method_rank <= 2 ORDER BY discovery_year, method_rank;\"\"\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rows(query):\n",
    "    cursor.execute(query)\n",
    "    rows = cursor.fetchall()\n",
    "    if not rows:\n",
    "        raise ValueError(f\"The following query returned no rows: {query}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, query in enumerate(sql_queries):\n",
    "    try:\n",
    "        test_rows(query)\n",
    "    except Exception as e:\n",
    "        print(f\"Look at idx: {idx+1}\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query(\"\"\"\n",
    "WITH detection_counts AS (\n",
    "    SELECT \n",
    "        detection_method, \n",
    "        COUNT(*) AS method_count\n",
    "    FROM \n",
    "        exoplanets\n",
    "    GROUP BY \n",
    "        detection_method\n",
    "),\n",
    "least_common_detection AS (\n",
    "    SELECT \n",
    "        detection_method\n",
    "    FROM \n",
    "        detection_counts\n",
    "    WHERE \n",
    "        method_count = (SELECT MIN(method_count) FROM detection_counts)\n",
    ")\n",
    "SELECT \n",
    "    e.*\n",
    "FROM \n",
    "    exoplanets e\n",
    "JOIN \n",
    "    least_common_detection lcd ON e.detection_method = lcd.detection_method;\n",
    "           \"\"\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rows(\"\"\"\n",
    "WITH detection_counts AS (\n",
    "    SELECT \n",
    "        detection_method, \n",
    "        COUNT(*) AS method_count\n",
    "    FROM \n",
    "        exoplanets\n",
    "    GROUP BY \n",
    "        detection_method\n",
    "),\n",
    "least_common_detection AS (\n",
    "    SELECT \n",
    "        detection_method\n",
    "    FROM \n",
    "        detection_counts\n",
    "    WHERE \n",
    "        method_count = (SELECT MIN(method_count) FROM detection_counts)\n",
    ")\n",
    "SELECT \n",
    "    e.*\n",
    "FROM \n",
    "    exoplanets e\n",
    "JOIN \n",
    "    least_common_detection lcd ON e.detection_method = lcd.detection_method;\n",
    "           \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_query(query, cursor):\n",
    "#     cursor.execute(query)\n",
    "#     rows = cursor.fetchall()\n",
    "#     columns = [desc[0] for desc in cursor.description]\n",
    "#     return pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "def run_query(query, cursor):\n",
    "    cursor.execute(query)\n",
    "    rows = cursor.fetchall()\n",
    "    columns = [desc[0] for desc in cursor.description]\n",
    "    result_dict = [dict(zip(columns, row)) for row in rows]\n",
    "    return json.dumps(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_query(sql_queries[0],cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_queries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_sql_df['results'] = generated_sql_df['answer'].map(lambda query: run_query(query,cursor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_sql_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "shuffled_df = generated_sql_df.sample(frac=1,random_state=42).reset_index(drop=True)#.rename(columns={'answer':'SQL'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    " # roll the dice via random seed but use judgement to get representative set \n",
    "train_df,valid_df = train_test_split(shuffled_df,test_size=10,random_state=177)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid_df.rename(columns={'answer':'SQL'},inplace=True)\n",
    "#train_df.rename(columns={'answer':'SQL'},inplace=True)\n",
    "#train_df.to_json('./databases/train.json',orient='records',lines=True)\n",
    "#valid_df.to_json('./databases/validation.json',orient='records',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrame to a list of dictionaries\n",
    "train_data = train_df.to_dict(orient='records')\n",
    "valid_data = valid_df.to_dict(orient='records')\n",
    "\n",
    "# Save the list of dictionaries to a JSON file\n",
    "with open('./databases/train.json', 'w') as train_file:\n",
    "    json.dump(train_data, train_file, indent=4)\n",
    "\n",
    "with open('./databases/valid.json', 'w') as valid_file:\n",
    "    json.dump(valid_data, valid_file, indent=4)\n",
    "\n",
    "# # Verify the saved JSON files\n",
    "# with open('./databases/train.json', 'r') as train_file:\n",
    "#     train_loaded = json.load(train_file)\n",
    "#     print(\"Train Data Loaded:\")\n",
    "#     print(train_loaded[:2])  # Print the first 2 records for verification\n",
    "\n",
    "# with open('./databases/valid.json', 'r') as valid_file:\n",
    "#     valid_loaded = json.load(valid_file)\n",
    "#     print(\"Valid Data Loaded:\")\n",
    "#     print(valid_loaded[:2])  # Print the first 2 records for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure to rename above if don't go building own evaluators approach fully\n",
    "from premsql.datasets import StandardDataset\n",
    "\n",
    "validation_dataset = StandardDataset(\n",
    "    split=\"validation\",    # it can be either train / validation / test depending on your dataset and the name of the json file\n",
    "    dataset_path=\"./databases\",\n",
    "    database_folder_name=\"databases\", # The same name of the folder \n",
    "    json_file_name=\"valid.json\",\n",
    ")\n",
    "\n",
    "train_dataset = StandardDataset(\n",
    "    split=\"train\",    # it can be either train / validation / test depending on your dataset and the name of the json file\n",
    "    dataset_path=\"./databases\",\n",
    "    database_folder_name=\"databases\", # The same name of the folder \n",
    "    json_file_name=\"train.json\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format as HF datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset('json', data_files='./databases/train.json', split='train')\n",
    "valid_dataset = load_dataset('json', data_files='./databases/valid.json', split='train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'valid': valid_dataset\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!huggingface-cli login\n",
    "dataset.push_to_hub('dpv/exoplanets-sql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, Repository\n",
    "api = HfApi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tried to update README.MD multiple times with the following:\n",
    "This is a small dataset based on https://www.kaggle.com/datasets/adityamishraml/nasaexoplanets/data.  sqlite table *exoplanets* was made from the data, along with a *reference_planets* table made by inserting  (name, mass) VALUES ('Jupiter', 1.898e27) and  (name, mass) VALUES ('Earth', 5.972e24).\n",
    "The *mass_wrt* column in *exoplanets* maps to *mass* table in *reference_planets*.  This table allows for more complex queries involving joins.  Queries have been checked for logical consistency, as well as by running against the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./hf_readme.md', \"r\") as file:\n",
    "    readme_content = file.read()\n",
    "\n",
    "# Update the README.md file on the Hugging Face Hub\n",
    "api.upload_file(\n",
    "    path_or_fileobj='./hf_readme.md',\n",
    "    path_in_repo=\"README.md\",\n",
    "    repo_id='dpv/exoplanets-sql',\n",
    "    repo_type=\"dataset\"\n",
    ")\n",
    "\n",
    "print(\"Updated README.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"\"\"WITH DetectionTrends AS (\n",
    "    SELECT \n",
    "        discovery_year,\n",
    "        detection_method,\n",
    "        COUNT(*) AS method_count\n",
    "    FROM exoplanets\n",
    "    GROUP BY discovery_year, detection_method\n",
    "),\n",
    "RankedTrends AS (\n",
    "    SELECT \n",
    "        discovery_year,\n",
    "        detection_method,\n",
    "        method_count, RANK() OVER (PARTITION BY discovery_year ORDER BY method_count DESC) AS method_rank FROM DetectionTrends) SELECT  discovery_year, detection_method, method_count, method_rank FROM RankedTrends WHERE method_rank <= 2 ORDER BY discovery_year, method_rank;\"\"\"\n",
    "\n",
    "query2 = \"\"\"WITH DetectionTrends AS (\n",
    "    SELECT \n",
    "        discovery_year,\n",
    "        detection_method,\n",
    "        COUNT(*) AS method_count\n",
    "    FROM exoplanets\n",
    "    GROUP BY discovery_year, detection_method\n",
    "),\n",
    "RankedTrends AS (\n",
    "    SELECT \n",
    "        discovery_year,\n",
    "        detection_method,\n",
    "        method_count, RANK() OVER (PARTITION BY discovery_year ORDER BY method_count DESC) AS method_rank FROM DetectionTrends) SELECT  discovery_year, detection_method, method_count, method_rank FROM RankedTrends WHERE method_rank <= 2 ORDER BY discovery_year DESC, method_rank;\"\"\"\n",
    "\n",
    "query3 = \"\"\"WITH DetectionTrends AS (\n",
    "    SELECT \n",
    "        discovery_year,\n",
    "        detection_method,\n",
    "        COUNT(*) AS method_count\n",
    "    FROM exoplanets\n",
    "    GROUP BY discovery_year, detection_method\n",
    "),\n",
    "RankedTrends AS (\n",
    "    SELECT \n",
    "        discovery_year,\n",
    "        detection_method,\n",
    "        method_count, RANK() OVER (PARTITION BY discovery_year ORDER BY method_count DESC) AS method_rank FROM DetectionTrends) SELECT  discovery_year, detection_method, method_count, method_rank FROM RankedTrends WHERE method_rank <= 3 ORDER BY discovery_year DESC, method_rank;\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"discovery_year\": 1992, \"detection_method\": \"Pulsar Timing\", \"method_count\": 2, \"method_rank\": 1}, {\"discovery_year\": 1994, \"detection_method\": \"Pulsar Timing\", \"method_count\": 1, \"method_rank\": 1}, {\"discovery_year\": 1995, \"detection_method\": \"Radial Velocity\", \"method_count\": 1, \"method_rank\": 1}, {\"discovery_year\": 1996, \"detection_method\": \"Radial Velocity\", \"method_count\": 6, \"method_rank\": 1}, {\"discovery_year\": 1997, \"detection_method\": \"Radial Velocity\", \"method_count\": 1, \"method_rank\": 1}, {\"discovery_year\": 1998, \"detection_method\": \"Radial Velocity\", \"method_count\": 6, \"method_rank\": 1}, {\"discovery_year\": 1999, \"detection_method\": \"Radial Velocity\", \"method_count\": 13, \"method_rank\": 1}, {\"discovery_year\": 2000, \"detection_method\": \"Radial Velocity\", \"method_count\": 16, \"method_rank\": 1}, {\"discovery_year\": 2001, \"detection_method\": \"Radial Velocity\", \"method_count\": 12, \"method_rank\": 1}, {\"discovery_year\": 2002, \"detection_method\": \"Radial Velocity\", \"method_count\": 28, \"method_rank\": 1}, {\"discovery_year\": 2002, \"detection_method\": \"Transit\", \"method_count\": 1, \"method_rank\": 2}, {\"discovery_year\": 2003, \"detection_method\": \"Radial Velocity\", \"method_count\": 21, \"method_rank\": 1}, {\"discovery_year\": 2003, \"detection_method\": \"Pulsar Timing\", \"method_count\": 1, \"method_rank\": 2}, {\"discovery_year\": 2004, \"detection_method\": \"Radial Velocity\", \"method_count\": 18, \"method_rank\": 1}, {\"discovery_year\": 2004, \"detection_method\": \"Transit\", \"method_count\": 5, \"method_rank\": 2}, {\"discovery_year\": 2005, \"detection_method\": \"Radial Velocity\", \"method_count\": 33, \"method_rank\": 1}, {\"discovery_year\": 2005, \"detection_method\": \"Gravitational Microlensing\", \"method_count\": 2, \"method_rank\": 2}, {\"discovery_year\": 2006, \"detection_method\": \"Radial Velocity\", \"method_count\": 21, \"method_rank\": 1}, {\"discovery_year\": 2006, \"detection_method\": \"Transit\", \"method_count\": 5, \"method_rank\": 2}, {\"discovery_year\": 2007, \"detection_method\": \"Radial Velocity\", \"method_count\": 34, \"method_rank\": 1}, {\"discovery_year\": 2007, \"detection_method\": \"Transit\", \"method_count\": 16, \"method_rank\": 2}, {\"discovery_year\": 2008, \"detection_method\": \"Radial Velocity\", \"method_count\": 37, \"method_rank\": 1}, {\"discovery_year\": 2008, \"detection_method\": \"Transit\", \"method_count\": 17, \"method_rank\": 2}, {\"discovery_year\": 2009, \"detection_method\": \"Radial Velocity\", \"method_count\": 73, \"method_rank\": 1}, {\"discovery_year\": 2009, \"detection_method\": \"Transit\", \"method_count\": 18, \"method_rank\": 2}, {\"discovery_year\": 2010, \"detection_method\": \"Transit\", \"method_count\": 46, \"method_rank\": 1}, {\"discovery_year\": 2010, \"detection_method\": \"Radial Velocity\", \"method_count\": 41, \"method_rank\": 2}, {\"discovery_year\": 2011, \"detection_method\": \"Transit\", \"method_count\": 79, \"method_rank\": 1}, {\"discovery_year\": 2011, \"detection_method\": \"Radial Velocity\", \"method_count\": 47, \"method_rank\": 2}, {\"discovery_year\": 2012, \"detection_method\": \"Transit\", \"method_count\": 93, \"method_rank\": 1}, {\"discovery_year\": 2012, \"detection_method\": \"Radial Velocity\", \"method_count\": 34, \"method_rank\": 2}, {\"discovery_year\": 2013, \"detection_method\": \"Transit\", \"method_count\": 80, \"method_rank\": 1}, {\"discovery_year\": 2013, \"detection_method\": \"Radial Velocity\", \"method_count\": 32, \"method_rank\": 2}, {\"discovery_year\": 2014, \"detection_method\": \"Transit\", \"method_count\": 802, \"method_rank\": 1}, {\"discovery_year\": 2014, \"detection_method\": \"Radial Velocity\", \"method_count\": 50, \"method_rank\": 2}, {\"discovery_year\": 2015, \"detection_method\": \"Transit\", \"method_count\": 100, \"method_rank\": 1}, {\"discovery_year\": 2015, \"detection_method\": \"Radial Velocity\", \"method_count\": 47, \"method_rank\": 2}, {\"discovery_year\": 2016, \"detection_method\": \"Transit\", \"method_count\": 1453, \"method_rank\": 1}, {\"discovery_year\": 2016, \"detection_method\": \"Radial Velocity\", \"method_count\": 50, \"method_rank\": 2}, {\"discovery_year\": 2017, \"detection_method\": \"Transit\", \"method_count\": 89, \"method_rank\": 1}, {\"discovery_year\": 2017, \"detection_method\": \"Radial Velocity\", \"method_count\": 49, \"method_rank\": 2}, {\"discovery_year\": 2018, \"detection_method\": \"Transit\", \"method_count\": 253, \"method_rank\": 1}, {\"discovery_year\": 2018, \"detection_method\": \"Radial Velocity\", \"method_count\": 49, \"method_rank\": 2}, {\"discovery_year\": 2019, \"detection_method\": \"Transit\", \"method_count\": 113, \"method_rank\": 1}, {\"discovery_year\": 2019, \"detection_method\": \"Radial Velocity\", \"method_count\": 66, \"method_rank\": 2}, {\"discovery_year\": 2020, \"detection_method\": \"Transit\", \"method_count\": 166, \"method_rank\": 1}, {\"discovery_year\": 2020, \"detection_method\": \"Radial Velocity\", \"method_count\": 45, \"method_rank\": 2}, {\"discovery_year\": 2021, \"detection_method\": \"Transit\", \"method_count\": 415, \"method_rank\": 1}, {\"discovery_year\": 2021, \"detection_method\": \"Radial Velocity\", \"method_count\": 78, \"method_rank\": 2}, {\"discovery_year\": 2022, \"detection_method\": \"Transit\", \"method_count\": 188, \"method_rank\": 1}, {\"discovery_year\": 2022, \"detection_method\": \"Radial Velocity\", \"method_count\": 116, \"method_rank\": 2}, {\"discovery_year\": 2023, \"detection_method\": \"Transit\", \"method_count\": 6, \"method_rank\": 1}, {\"discovery_year\": 2023, \"detection_method\": \"Radial Velocity\", \"method_count\": 3, \"method_rank\": 2}]'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1=run_query(query1,cursor)\n",
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"discovery_year\": 2023, \"detection_method\": \"Transit\", \"method_count\": 6, \"method_rank\": 1}, {\"discovery_year\": 2023, \"detection_method\": \"Radial Velocity\", \"method_count\": 3, \"method_rank\": 2}, {\"discovery_year\": 2022, \"detection_method\": \"Transit\", \"method_count\": 188, \"method_rank\": 1}, {\"discovery_year\": 2022, \"detection_method\": \"Radial Velocity\", \"method_count\": 116, \"method_rank\": 2}, {\"discovery_year\": 2021, \"detection_method\": \"Transit\", \"method_count\": 415, \"method_rank\": 1}, {\"discovery_year\": 2021, \"detection_method\": \"Radial Velocity\", \"method_count\": 78, \"method_rank\": 2}, {\"discovery_year\": 2020, \"detection_method\": \"Transit\", \"method_count\": 166, \"method_rank\": 1}, {\"discovery_year\": 2020, \"detection_method\": \"Radial Velocity\", \"method_count\": 45, \"method_rank\": 2}, {\"discovery_year\": 2019, \"detection_method\": \"Transit\", \"method_count\": 113, \"method_rank\": 1}, {\"discovery_year\": 2019, \"detection_method\": \"Radial Velocity\", \"method_count\": 66, \"method_rank\": 2}, {\"discovery_year\": 2018, \"detection_method\": \"Transit\", \"method_count\": 253, \"method_rank\": 1}, {\"discovery_year\": 2018, \"detection_method\": \"Radial Velocity\", \"method_count\": 49, \"method_rank\": 2}, {\"discovery_year\": 2017, \"detection_method\": \"Transit\", \"method_count\": 89, \"method_rank\": 1}, {\"discovery_year\": 2017, \"detection_method\": \"Radial Velocity\", \"method_count\": 49, \"method_rank\": 2}, {\"discovery_year\": 2016, \"detection_method\": \"Transit\", \"method_count\": 1453, \"method_rank\": 1}, {\"discovery_year\": 2016, \"detection_method\": \"Radial Velocity\", \"method_count\": 50, \"method_rank\": 2}, {\"discovery_year\": 2015, \"detection_method\": \"Transit\", \"method_count\": 100, \"method_rank\": 1}, {\"discovery_year\": 2015, \"detection_method\": \"Radial Velocity\", \"method_count\": 47, \"method_rank\": 2}, {\"discovery_year\": 2014, \"detection_method\": \"Transit\", \"method_count\": 802, \"method_rank\": 1}, {\"discovery_year\": 2014, \"detection_method\": \"Radial Velocity\", \"method_count\": 50, \"method_rank\": 2}, {\"discovery_year\": 2013, \"detection_method\": \"Transit\", \"method_count\": 80, \"method_rank\": 1}, {\"discovery_year\": 2013, \"detection_method\": \"Radial Velocity\", \"method_count\": 32, \"method_rank\": 2}, {\"discovery_year\": 2012, \"detection_method\": \"Transit\", \"method_count\": 93, \"method_rank\": 1}, {\"discovery_year\": 2012, \"detection_method\": \"Radial Velocity\", \"method_count\": 34, \"method_rank\": 2}, {\"discovery_year\": 2011, \"detection_method\": \"Transit\", \"method_count\": 79, \"method_rank\": 1}, {\"discovery_year\": 2011, \"detection_method\": \"Radial Velocity\", \"method_count\": 47, \"method_rank\": 2}, {\"discovery_year\": 2010, \"detection_method\": \"Transit\", \"method_count\": 46, \"method_rank\": 1}, {\"discovery_year\": 2010, \"detection_method\": \"Radial Velocity\", \"method_count\": 41, \"method_rank\": 2}, {\"discovery_year\": 2009, \"detection_method\": \"Radial Velocity\", \"method_count\": 73, \"method_rank\": 1}, {\"discovery_year\": 2009, \"detection_method\": \"Transit\", \"method_count\": 18, \"method_rank\": 2}, {\"discovery_year\": 2008, \"detection_method\": \"Radial Velocity\", \"method_count\": 37, \"method_rank\": 1}, {\"discovery_year\": 2008, \"detection_method\": \"Transit\", \"method_count\": 17, \"method_rank\": 2}, {\"discovery_year\": 2007, \"detection_method\": \"Radial Velocity\", \"method_count\": 34, \"method_rank\": 1}, {\"discovery_year\": 2007, \"detection_method\": \"Transit\", \"method_count\": 16, \"method_rank\": 2}, {\"discovery_year\": 2006, \"detection_method\": \"Radial Velocity\", \"method_count\": 21, \"method_rank\": 1}, {\"discovery_year\": 2006, \"detection_method\": \"Transit\", \"method_count\": 5, \"method_rank\": 2}, {\"discovery_year\": 2005, \"detection_method\": \"Radial Velocity\", \"method_count\": 33, \"method_rank\": 1}, {\"discovery_year\": 2005, \"detection_method\": \"Gravitational Microlensing\", \"method_count\": 2, \"method_rank\": 2}, {\"discovery_year\": 2004, \"detection_method\": \"Radial Velocity\", \"method_count\": 18, \"method_rank\": 1}, {\"discovery_year\": 2004, \"detection_method\": \"Transit\", \"method_count\": 5, \"method_rank\": 2}, {\"discovery_year\": 2003, \"detection_method\": \"Radial Velocity\", \"method_count\": 21, \"method_rank\": 1}, {\"discovery_year\": 2003, \"detection_method\": \"Pulsar Timing\", \"method_count\": 1, \"method_rank\": 2}, {\"discovery_year\": 2002, \"detection_method\": \"Radial Velocity\", \"method_count\": 28, \"method_rank\": 1}, {\"discovery_year\": 2002, \"detection_method\": \"Transit\", \"method_count\": 1, \"method_rank\": 2}, {\"discovery_year\": 2001, \"detection_method\": \"Radial Velocity\", \"method_count\": 12, \"method_rank\": 1}, {\"discovery_year\": 2000, \"detection_method\": \"Radial Velocity\", \"method_count\": 16, \"method_rank\": 1}, {\"discovery_year\": 1999, \"detection_method\": \"Radial Velocity\", \"method_count\": 13, \"method_rank\": 1}, {\"discovery_year\": 1998, \"detection_method\": \"Radial Velocity\", \"method_count\": 6, \"method_rank\": 1}, {\"discovery_year\": 1997, \"detection_method\": \"Radial Velocity\", \"method_count\": 1, \"method_rank\": 1}, {\"discovery_year\": 1996, \"detection_method\": \"Radial Velocity\", \"method_count\": 6, \"method_rank\": 1}, {\"discovery_year\": 1995, \"detection_method\": \"Radial Velocity\", \"method_count\": 1, \"method_rank\": 1}, {\"discovery_year\": 1994, \"detection_method\": \"Pulsar Timing\", \"method_count\": 1, \"method_rank\": 1}, {\"discovery_year\": 1992, \"detection_method\": \"Pulsar Timing\", \"method_count\": 2, \"method_rank\": 1}]'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2=run_query(query2, cursor)\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"discovery_year\": 2023, \"detection_method\": \"Transit\", \"method_count\": 6, \"method_rank\": 1}, {\"discovery_year\": 2023, \"detection_method\": \"Radial Velocity\", \"method_count\": 3, \"method_rank\": 2}, {\"discovery_year\": 2022, \"detection_method\": \"Transit\", \"method_count\": 188, \"method_rank\": 1}, {\"discovery_year\": 2022, \"detection_method\": \"Radial Velocity\", \"method_count\": 116, \"method_rank\": 2}, {\"discovery_year\": 2022, \"detection_method\": \"Gravitational Microlensing\", \"method_count\": 25, \"method_rank\": 3}, {\"discovery_year\": 2021, \"detection_method\": \"Transit\", \"method_count\": 415, \"method_rank\": 1}, {\"discovery_year\": 2021, \"detection_method\": \"Radial Velocity\", \"method_count\": 78, \"method_rank\": 2}, {\"discovery_year\": 2021, \"detection_method\": \"Gravitational Microlensing\", \"method_count\": 20, \"method_rank\": 3}, {\"discovery_year\": 2020, \"detection_method\": \"Transit\", \"method_count\": 166, \"method_rank\": 1}, {\"discovery_year\": 2020, \"detection_method\": \"Radial Velocity\", \"method_count\": 45, \"method_rank\": 2}, {\"discovery_year\": 2020, \"detection_method\": \"Gravitational Microlensing\", \"method_count\": 20, \"method_rank\": 3}, {\"discovery_year\": 2019, \"detection_method\": \"Transit\", \"method_count\": 113, \"method_rank\": 1}, {\"discovery_year\": 2019, \"detection_method\": \"Radial Velocity\", \"method_count\": 66, \"method_rank\": 2}, {\"discovery_year\": 2019, \"detection_method\": \"Gravitational Microlensing\", \"method_count\": 14, \"method_rank\": 3}, {\"discovery_year\": 2018, \"detection_method\": \"Transit\", \"method_count\": 253, \"method_rank\": 1}, {\"discovery_year\": 2018, \"detection_method\": \"Radial Velocity\", \"method_count\": 49, \"method_rank\": 2}, {\"discovery_year\": 2018, \"detection_method\": \"Gravitational Microlensing\", \"method_count\": 21, \"method_rank\": 3}, {\"discovery_year\": 2017, \"detection_method\": \"Transit\", \"method_count\": 89, \"method_rank\": 1}, {\"discovery_year\": 2017, \"detection_method\": \"Radial Velocity\", \"method_count\": 49, \"method_rank\": 2}, {\"discovery_year\": 2017, \"detection_method\": \"Gravitational Microlensing\", \"method_count\": 9, \"method_rank\": 3}, {\"discovery_year\": 2016, \"detection_method\": \"Transit\", \"method_count\": 1453, \"method_rank\": 1}, {\"discovery_year\": 2016, \"detection_method\": \"Radial Velocity\", \"method_count\": 50, \"method_rank\": 2}, {\"discovery_year\": 2016, \"detection_method\": \"Gravitational Microlensing\", \"method_count\": 10, \"method_rank\": 3}, {\"discovery_year\": 2015, \"detection_method\": \"Transit\", \"method_count\": 100, \"method_rank\": 1}, {\"discovery_year\": 2015, \"detection_method\": \"Radial Velocity\", \"method_count\": 47, \"method_rank\": 2}, {\"discovery_year\": 2015, \"detection_method\": \"Direct Imaging\", \"method_count\": 5, \"method_rank\": 3}, {\"discovery_year\": 2014, \"detection_method\": \"Transit\", \"method_count\": 802, \"method_rank\": 1}, {\"discovery_year\": 2014, \"detection_method\": \"Radial Velocity\", \"method_count\": 50, \"method_rank\": 2}, {\"discovery_year\": 2014, \"detection_method\": \"Transit Timing Variations\", \"method_count\": 12, \"method_rank\": 3}, {\"discovery_year\": 2013, \"detection_method\": \"Transit\", \"method_count\": 80, \"method_rank\": 1}, {\"discovery_year\": 2013, \"detection_method\": \"Radial Velocity\", \"method_count\": 32, \"method_rank\": 2}, {\"discovery_year\": 2013, \"detection_method\": \"Direct Imaging\", \"method_count\": 7, \"method_rank\": 3}, {\"discovery_year\": 2012, \"detection_method\": \"Transit\", \"method_count\": 93, \"method_rank\": 1}, {\"discovery_year\": 2012, \"detection_method\": \"Radial Velocity\", \"method_count\": 34, \"method_rank\": 2}, {\"discovery_year\": 2012, \"detection_method\": \"Gravitational Microlensing\", \"method_count\": 7, \"method_rank\": 3}, {\"discovery_year\": 2011, \"detection_method\": \"Transit\", \"method_count\": 79, \"method_rank\": 1}, {\"discovery_year\": 2011, \"detection_method\": \"Radial Velocity\", \"method_count\": 47, \"method_rank\": 2}, {\"discovery_year\": 2011, \"detection_method\": \"Eclipse Timing Variations\", \"method_count\": 5, \"method_rank\": 3}, {\"discovery_year\": 2010, \"detection_method\": \"Transit\", \"method_count\": 46, \"method_rank\": 1}, {\"discovery_year\": 2010, \"detection_method\": \"Radial Velocity\", \"method_count\": 41, \"method_rank\": 2}, {\"discovery_year\": 2010, \"detection_method\": \"Direct Imaging\", \"method_count\": 6, \"method_rank\": 3}, {\"discovery_year\": 2009, \"detection_method\": \"Radial Velocity\", \"method_count\": 73, \"method_rank\": 1}, {\"discovery_year\": 2009, \"detection_method\": \"Transit\", \"method_count\": 18, \"method_rank\": 2}, {\"discovery_year\": 2009, \"detection_method\": \"Gravitational Microlensing\", \"method_count\": 2, \"method_rank\": 3}, {\"discovery_year\": 2008, \"detection_method\": \"Radial Velocity\", \"method_count\": 37, \"method_rank\": 1}, {\"discovery_year\": 2008, \"detection_method\": \"Transit\", \"method_count\": 17, \"method_rank\": 2}, {\"discovery_year\": 2008, \"detection_method\": \"Direct Imaging\", \"method_count\": 7, \"method_rank\": 3}, {\"discovery_year\": 2007, \"detection_method\": \"Radial Velocity\", \"method_count\": 34, \"method_rank\": 1}, {\"discovery_year\": 2007, \"detection_method\": \"Transit\", \"method_count\": 16, \"method_rank\": 2}, {\"discovery_year\": 2007, \"detection_method\": \"Direct Imaging\", \"method_count\": 1, \"method_rank\": 3}, {\"discovery_year\": 2007, \"detection_method\": \"Pulsation Timing Variations\", \"method_count\": 1, \"method_rank\": 3}, {\"discovery_year\": 2006, \"detection_method\": \"Radial Velocity\", \"method_count\": 21, \"method_rank\": 1}, {\"discovery_year\": 2006, \"detection_method\": \"Transit\", \"method_count\": 5, \"method_rank\": 2}, {\"discovery_year\": 2006, \"detection_method\": \"Direct Imaging\", \"method_count\": 4, \"method_rank\": 3}, {\"discovery_year\": 2005, \"detection_method\": \"Radial Velocity\", \"method_count\": 33, \"method_rank\": 1}, {\"discovery_year\": 2005, \"detection_method\": \"Gravitational Microlensing\", \"method_count\": 2, \"method_rank\": 2}, {\"discovery_year\": 2005, \"detection_method\": \"Direct Imaging\", \"method_count\": 1, \"method_rank\": 3}, {\"discovery_year\": 2004, \"detection_method\": \"Radial Velocity\", \"method_count\": 18, \"method_rank\": 1}, {\"discovery_year\": 2004, \"detection_method\": \"Transit\", \"method_count\": 5, \"method_rank\": 2}, {\"discovery_year\": 2004, \"detection_method\": \"Direct Imaging\", \"method_count\": 3, \"method_rank\": 3}, {\"discovery_year\": 2003, \"detection_method\": \"Radial Velocity\", \"method_count\": 21, \"method_rank\": 1}, {\"discovery_year\": 2003, \"detection_method\": \"Pulsar Timing\", \"method_count\": 1, \"method_rank\": 2}, {\"discovery_year\": 2002, \"detection_method\": \"Radial Velocity\", \"method_count\": 28, \"method_rank\": 1}, {\"discovery_year\": 2002, \"detection_method\": \"Transit\", \"method_count\": 1, \"method_rank\": 2}, {\"discovery_year\": 2001, \"detection_method\": \"Radial Velocity\", \"method_count\": 12, \"method_rank\": 1}, {\"discovery_year\": 2000, \"detection_method\": \"Radial Velocity\", \"method_count\": 16, \"method_rank\": 1}, {\"discovery_year\": 1999, \"detection_method\": \"Radial Velocity\", \"method_count\": 13, \"method_rank\": 1}, {\"discovery_year\": 1998, \"detection_method\": \"Radial Velocity\", \"method_count\": 6, \"method_rank\": 1}, {\"discovery_year\": 1997, \"detection_method\": \"Radial Velocity\", \"method_count\": 1, \"method_rank\": 1}, {\"discovery_year\": 1996, \"detection_method\": \"Radial Velocity\", \"method_count\": 6, \"method_rank\": 1}, {\"discovery_year\": 1995, \"detection_method\": \"Radial Velocity\", \"method_count\": 1, \"method_rank\": 1}, {\"discovery_year\": 1994, \"detection_method\": \"Pulsar Timing\", \"method_count\": 1, \"method_rank\": 1}, {\"discovery_year\": 1992, \"detection_method\": \"Pulsar Timing\", \"method_count\": 2, \"method_rank\": 1}]'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res3=run_query(query3, cursor)\n",
    "res3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check query equivalence\n",
    "def parse_results(results_json):\n",
    "    \"\"\"Parse the JSON results from the 'results' column.\"\"\"\n",
    "    return json.loads(results_json)\n",
    "\n",
    "def compare_results(query_results, expected_results):\n",
    "    \"\"\"Compare the query results with the expected results.\"\"\"\n",
    "    # Sort the results for comparison\n",
    "    query_results_sorted = sorted(query_results, key=lambda x: json.dumps(x, sort_keys=True))\n",
    "    expected_results_sorted = sorted(expected_results, key=lambda x: json.dumps(x, sort_keys=True))\n",
    "    return query_results_sorted == expected_results_sorted\n",
    "\n",
    "def check_query_equivalence(query, expected_results_json, cursor):\n",
    "    \"\"\"Check if the query results are equivalent to the expected results.\"\"\"\n",
    "    query_results = run_query(query, cursor)\n",
    "    return compare_results(query_results, expected_results_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_results(res1,res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_results(res1,res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_query_equivalence(query1,res1,cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_query_equivalence(query1,res3,cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use OperationalError to mark queries that didn't execute; really work on having output only return SQL or parsing out the SQL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch; torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from premsql.executors.from_sqlite import SQLiteExecutor\n",
    "# from premsql.datasets import Text2SQLDataset\n",
    "# from premsql.tuner.peft import Text2SQLPeftTuner\n",
    "# from premsql.datasets.error_dataset import ErrorDatasetGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate from a ready model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"CREATE TABLE exoplanets (\n",
    "    name TEXT,\n",
    "    distance REAL,\n",
    "    stellar_magnitude REAL,\n",
    "    planet_type TEXT,\n",
    "    discovery_year INTEGER,\n",
    "    mass_multiplier REAL,\n",
    "    mass_wrt TEXT,\n",
    "    radius_multiplier REAL,\n",
    "    radius_wrt TEXT,\n",
    "    orbital_radius REAL,\n",
    "    orbital_period REAL,\n",
    "    eccentricity REAL,\n",
    "    detection_method TEXT\n",
    "); CREATE TABLE reference_planets (name TEXT, mass REAL);  'mass_wrt' in exoplanets table has a one-to-one match to 'name' in reference_planets table, and  'name' refers to either Earth or Jupyter, with Jupyter having 317.8 the mass of Earth.\"\"\"\n",
    "\n",
    "question = \"\"\"Rank exoplanets based on their mass within each discovery year and return the top 3 planets with the highest mass.\"\"\"\n",
    "answer = \"\"\"WITH RankedExoplanets AS (\n",
    "    SELECT \n",
    "        e.name,\n",
    "        e.mass_multiplier * r.mass AS mass,\n",
    "        e.discovery_year,\n",
    "        RANK() OVER (PARTITION BY e.discovery_year ORDER BY e.mass_multiplier * r.mass DESC) AS mass_rank\n",
    "    FROM exoplanets e\n",
    "    JOIN reference_planets r ON e.mass_wrt = r.name\n",
    ")\n",
    "\n",
    "SELECT * \n",
    "FROM RankedExoplanets\n",
    "WHERE mass_rank <= 3; \"\"\"\n",
    "full_question = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "You are a helpful assistant who is a SQL expert. Your task is to write a SQL query based on the given context and question.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>SQL Query:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mainuser/anaconda3/envs/sqlft/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Unrecognized keys in `rope_scaling` for 'rope_type'='linear': {'type'}\n",
      "Loading checkpoint shards: 100%|| 2/2 [00:00<00:00, 11.24it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "MODEL_ID=\"premai-io/prem-1B-SQL\"\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_ID).to(\"cuda:1\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32256, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5504, bias=False)\n",
       "          (down_proj): Linear(in_features=5504, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-06)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-06)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=32256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='premai-io/prem-1B-SQL', vocab_size=32000, model_max_length=16384, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<beginofsentence>', 'eos_token': '<|EOT|>', 'pad_token': '<endofsentence>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t32000: AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32001: AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32002: AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32003: AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32004: AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32005: AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32006: AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32007: AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32008: AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32009: AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32010: AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32011: AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32012: AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32013: AddedToken(\"<beginofsentence>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t32014: AddedToken(\"<endofsentence>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t32015: AddedToken(\"<fimhole>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32016: AddedToken(\"<fimbegin>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32017: AddedToken(\"<fimend>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32018: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32019: AddedToken(\"<|User|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32020: AddedToken(\"<|Assistant|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32021: AddedToken(\"<|EOT|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='premai-io/prem-1B-SQL', vocab_size=32000, model_max_length=16384, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<beginofsentence>', 'eos_token': '<|EOT|>', 'pad_token': '<endofsentence>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t32000: AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32001: AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32002: AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32003: AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32004: AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32005: AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32006: AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32007: AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32008: AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32009: AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32010: AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32011: AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32012: AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32013: AddedToken(\"<beginofsentence>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t32014: AddedToken(\"<endofsentence>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t32015: AddedToken(\"<fimhole>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32016: AddedToken(\"<fimbegin>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32017: AddedToken(\"<fimend>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32018: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32019: AddedToken(\"<|User|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32020: AddedToken(\"<|Assistant|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t32021: AddedToken(\"<|EOT|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def generate_sql(context, question, max_new_tokens = 256, debug=False):\n",
    "    full_question = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "You are a helpful assistant who is a SQL expert. Your task is to write a SQL query based on the given context and question.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>SQL Query:\"\"\"\n",
    "    model_input = tokenizer(full_question, return_tensors=\"pt\").to(\"cuda:1\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = tokenizer.decode(model.generate(**model_input,max_new_tokens=max_new_tokens)[0],skip_special_tokens=True)\n",
    "    res = out[out.find('SQL Query:')+11:]\n",
    "    if debug: print(res)\n",
    "    run_query(res, cursor)\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# BAD, BAD, BAD\n",
    "def generate_sql(context, question, max_new_tokens = 256, debug=False):\n",
    "    full_question = f\"\"\"<|begin_of_sentence|>\n",
    "\n",
    "System: You are a helpful assistant who is a SQL expert. Your task is to write a SQL query based on the given context and question.\n",
    "<|User|>\n",
    "Context: {context}\n",
    "Question: {question}<|EOT|>\n",
    "<|Assistant|>\n",
    "SQL Query:<fimbegin>\"\"\"\n",
    "    model_input = tokenizer(full_question, return_tensors=\"pt\").to(\"cuda:1\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = tokenizer.decode(model.generate(**model_input,max_new_tokens=max_new_tokens)[0],skip_special_tokens=True)\n",
    "    res = out[out.find('SQL Query:')+11:]\n",
    "    if debug: print(res)\n",
    "    run_query(res, cursor)\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mout\u001b[49m[out\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSQL Query:\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m11\u001b[39m:]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(res)\n\u001b[1;32m      3\u001b[0m run_query(res, cursor)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'out' is not defined"
     ]
    }
   ],
   "source": [
    "res = out[out.find('SQL Query:')+11:]\n",
    "print(res)\n",
    "run_query(res, cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now generalize it to run on every query in valid set and get the results, counting OperationalError (query valid against db?), and perhaps starting to count execution accuracy (query accurate?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Data Loaded:\n",
      "[{'context': \"CREATE TABLE exoplanets (\\n    name TEXT,\\n    distance REAL,\\n    stellar_magnitude REAL,\\n    planet_type TEXT,\\n    discovery_year INTEGER,\\n    mass_multiplier REAL,\\n    mass_wrt TEXT,\\n    radius_multiplier REAL,\\n    radius_wrt TEXT,\\n    orbital_radius REAL,\\n    orbital_period REAL,\\n    eccentricity REAL,\\n    detection_method TEXT\\n); CREATE TABLE reference_planets (name TEXT, mass REAL);  'mass_wrt' in exoplanets table has a one-to-one match to 'name' in reference_planets table, and  'name' refers to either Earth or Jupyter, with Jupyter having 317.8 the mass of Earth.\", 'question': 'Determine the number of exoplanets discovered each year, and show the year with the highest number of discoveries.', 'answer': 'SELECT discovery_year, COUNT(*) AS count\\nFROM exoplanets\\nGROUP BY discovery_year\\nORDER BY count DESC\\nLIMIT 1;', 'results': '[{\"discovery_year\": 2016, \"count\": 1517}]'}, {'context': \"CREATE TABLE exoplanets (\\n    name TEXT,\\n    distance REAL,\\n    stellar_magnitude REAL,\\n    planet_type TEXT,\\n    discovery_year INTEGER,\\n    mass_multiplier REAL,\\n    mass_wrt TEXT,\\n    radius_multiplier REAL,\\n    radius_wrt TEXT,\\n    orbital_radius REAL,\\n    orbital_period REAL,\\n    eccentricity REAL,\\n    detection_method TEXT\\n); CREATE TABLE reference_planets (name TEXT, mass REAL);  'mass_wrt' in exoplanets table has a one-to-one match to 'name' in reference_planets table, and  'name' refers to either Earth or Jupyter, with Jupyter having 317.8 the mass of Earth.\", 'question': 'Display the detection method that has produced the most massive exoplanets (based on total mass).', 'answer': 'SELECT detection_method,\\n       SUM(mass_multiplier * (SELECT mass FROM reference_planets WHERE name = mass_wrt)) AS total_mass\\nFROM exoplanets\\nGROUP BY detection_method\\nORDER BY total_mass DESC\\nLIMIT 1;', 'results': '[{\"detection_method\": \"Radial Velocity\", \"total_mass\": 6.38296985206948e+30}]'}]\n"
     ]
    }
   ],
   "source": [
    "with open('./databases/valid.json', 'r') as valid_file:\n",
    "    valid_loaded = json.load(valid_file)\n",
    "    print(\"Valid Data Loaded:\")\n",
    "    print(valid_loaded[:2])  # Print the first 2 records for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fimbegin>SELECT discovery_year, COUNT(*) as num_exoplanets FROM exoplanets GROUP BY discovery_year ORDER BY num_exoplanets DESC LIMIT 1;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fimbegin>SELECT detection_method FROM exoplanets WHERE mass_wrt = (SELECT name FROM reference_planets WHERE mass = 317.8) ORDER BY mass DESC LIMIT 1;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fimbegin>SELECT discovery_year, SUM(mass) OVER (PARTITION BY discovery_year) AS total_mass FROM exoplanets ORDER BY total_mass DESC LIMIT 5;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fimbegin>SELECT name, orbital_period, discovery_year FROM (SELECT name, orbital_period, discovery_year, ROW_NUMBER() OVER (PARTITION BY discovery_year ORDER BY orbital_period DESC) as rn FROM exoplanets) t WHERE rn <= 3;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fimbegin>SELECT * FROM exoplanets WHERE discovery_year < 2000 AND eccentricity < 0.2;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fimbegin>SELECT DISTINCT planet_type FROM exoplanets WHERE discovery_year < 2020;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fimbegin>SELECT name, mass FROM (SELECT name, mass, discovery_year, MIN(mass) OVER (PARTITION BY discovery_year) as min_mass FROM exoplanets) WHERE mass = min_mass;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fimbegin>SELECT name, discovery_year, detection_method FROM exoplanets WHERE discovery_year BETWEEN (SELECT MAX(discovery_year) - 2 FROM exoplanets) AND MAX(discovery_year);\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fimbegin>SELECT planet_type, AVG(orbital_radius) AS avg_orbital_radius FROM exoplanets GROUP BY planet_type ORDER BY avg_orbital_radius DESC;\n",
      "fimbegin>SELECT name, (mass_wrt::REAL / radius_wrt::REAL) AS ratio FROM exoplanets ORDER BY ratio DESC LIMIT 5;\n",
      "num_opp_errors: 10, num_other_exceptions:0,\n",
      "Error rate: 100.0\n"
     ]
    }
   ],
   "source": [
    "num_opp_errors = 0\n",
    "num_other_exceptions = 0\n",
    "for example in valid_loaded:\n",
    "    try:\n",
    "        generate_sql(context=example['context'], question=example['question'],debug=True)\n",
    "    except sqlite3.OperationalError:\n",
    "        num_opp_errors += 1\n",
    "    except Exception as e:\n",
    "        num_other_exceptions +=1\n",
    "        print(e)\n",
    "print(f\"num_opp_errors: {num_opp_errors}, num_other_exceptions:{num_other_exceptions},\\nError rate: {(num_other_exceptions+num_opp_errors)*100/len(valid_loaded)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now see if can convert Gretl data to sqlite format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install \"sqlglot[rs]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlglot\n",
    "sqlglot.transpile(\"SELECT EPOCH_MS(1618088028295)\", read=\"mysql\", write=\"sqlite\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(sqlglot.transpile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlglot\n",
    "sqlglot.transpile(\"SELECT AVG(word_count) OVER (PARTITION BY EXTRACT(YEAR_QUARTER FROM publish_date)) AS avg_word_count FROM articles WHERE category = 'social_justice' AND location = 'USA' AND YEAR(publish_date) BETWEEN 2021 AND 2022;\", read=\"mysql\", write=\"sqlite\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install premsql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from premsql.pipelines.simple import SimpleText2SQLAgent\n",
    "from premsql.generators.huggingface import Text2SQLGeneratorHF\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "from premsql.utils import convert_sqlite_path_to_dsn\n",
    "\n",
    "dsn_or_db_path = convert_sqlite_path_to_dsn(\n",
    "  \"exoplanets_db.db\"   \n",
    ")\n",
    "db = SQLDatabase.from_uri(dsn_or_db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tabulate\n",
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See if can use llama3b (currently no) and prem-1B-SQL to generate answers by connecting to db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = SimpleText2SQLAgent(\n",
    "    dsn_or_db_path=db,\n",
    "    generator=Text2SQLGeneratorHF(\n",
    "        model_or_name_or_path=\"premai-io/prem-1B-SQL\",\n",
    "        #model_or_name_or_path=\"llama3-3b\",\n",
    "        experiment_name=\"test_nli\",\n",
    "        device=\"cuda:0\",\n",
    "        type=\"test\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.query(\n",
    "    question=\"please list the most recently discovered exoplanet\",\n",
    "    do_sample = True\n",
    ")\n",
    "\n",
    "response[\"table\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.query(\n",
    "    question=\"please list the most recently discovered exoplanet\",\n",
    "    do_sample = True\n",
    ")\n",
    "\n",
    "response[\"table\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "print(\"Tables in the database:\")\n",
    "for table in tables:\n",
    "    print(table[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consider generating more questions from seed of 20 programmatically: TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Sample dataset of questions and queries\n",
    "questions = [\n",
    "    {\n",
    "        \"question\": \"What is the average mass of exoplanets discovered each year?\",\n",
    "        \"query\": \"SELECT discovery_year, AVG(mass) FROM exoplanets GROUP BY discovery_year;\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How many exoplanets were discovered using each method?\",\n",
    "        \"query\": \"SELECT detection_method, COUNT(*) FROM exoplanets GROUP BY detection_method;\"\n",
    "    },\n",
    "    # Add more questions and queries...\n",
    "]\n",
    "\n",
    "# Example of variable options to permute\n",
    "variables = {\n",
    "    \"threshold\": [5, 10, 15],\n",
    "    \"column\": [\"stellar_magnitude\", \"distance\", \"orbital_period\"],\n",
    "    \"aggregate\": [\"AVG\", \"COUNT\", \"SUM\"],\n",
    "}\n",
    "\n",
    "# Function to create permutations\n",
    "def generate_permutations(questions, variables):\n",
    "    new_questions = []\n",
    "    for item in questions:\n",
    "        for threshold in variables[\"threshold\"]:\n",
    "            for column in variables[\"column\"]:\n",
    "                for agg in variables[\"aggregate\"]:\n",
    "                    # Create a new question and query\n",
    "                    new_question = item[\"question\"].replace(\"average mass\", f\"{agg.lower()} {column}\") + f\" (threshold: {threshold})\"\n",
    "                    new_query = item[\"query\"].replace(\"AVG(mass)\", f\"{agg}({column})\").replace(\"WHERE ...\", f\"WHERE {column} > {threshold}\")\n",
    "                    \n",
    "                    new_questions.append({\n",
    "                        \"question\": new_question,\n",
    "                        \"query\": new_query\n",
    "                    })\n",
    "    return new_questions\n",
    "\n",
    "# Generate new questions and queries\n",
    "new_dataset = generate_permutations(questions, variables)\n",
    "\n",
    "# Display new questions and queries\n",
    "for item in new_dataset:\n",
    "    print(f\"Question: {item['question']}\")\n",
    "    print(f\"SQL Query: {item['query']}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODOs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- expand data generation from seed (50-100 examples), all tested\n",
    "- sqglot exector or premai executor (experiment)-> Unit tests\n",
    "- other ways to write unit tests?  see Hammel\n",
    "- decide on finetuning approach; with whatever approach must be able to test against db, so see if can test llama3-3b against db or finetune prem in full precision perhaps (just on my data)\n",
    "- sqlite android/ios integration and emulator testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sqlft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
